{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "StopwordBetaW.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJTj3LuhiIDT"
      },
      "source": [
        "# Data Mining 2020/2021 | Universitas AMIKOM Yogyakarta\n",
        "### Pre-processing - Stopwords Removal\n",
        "#### Name: Beta Wulandari\n",
        "#### Student ID: 18.61.0138"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDO79GysnqPF",
        "outputId": "6794e9e0-5ced-4fcb-c36b-a7a485c07b82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "!pip install Sastrawi #added by beta"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Sastrawi\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/4b/bab676953da3103003730b8fcdfadbdd20f333d4add10af949dd5c51e6ed/Sastrawi-1.0.1-py2.py3-none-any.whl (209kB)\n",
            "\r\u001b[K     |█▋                              | 10kB 17.9MB/s eta 0:00:01\r\u001b[K     |███▏                            | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |████▊                           | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 40kB 2.5MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 61kB 2.2MB/s eta 0:00:01\r\u001b[K     |███████████                     | 71kB 2.4MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 81kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 92kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 194kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 204kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 215kB 2.8MB/s \n",
            "\u001b[?25hInstalling collected packages: Sastrawi\n",
            "Successfully installed Sastrawi-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfD1ifNCnyvi"
      },
      "source": [
        "import nltk #import library nltk\n",
        "from nltk.tokenize import word_tokenize #import word_tokenize for tokenizing text into words \n",
        "from nltk.tokenize import sent_tokenize #import sent_tokenize for tokenizing paragraph into sentences\n",
        "from nltk.stem.porter import PorterStemmer #import Porter Stemmer Algorithm \n",
        "from nltk.stem import WordNetLemmatizer #import WordNet lemmatizer \n",
        "from nltk.corpus import stopwords #import stopwords\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory #import Indonesian Stemmer\n",
        "import re #import regular expression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5vCRP1LoCfL",
        "outputId": "63c66d7e-23d4-4915-a0a3-e498f3e86eea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory #added by beta\n",
        "factory = StopWordRemoverFactory()\n",
        "stopwords = factory.get_stop_words()\n",
        "print(stopwords)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['yang', 'untuk', 'pada', 'ke', 'para', 'namun', 'menurut', 'antara', 'dia', 'dua', 'ia', 'seperti', 'jika', 'jika', 'sehingga', 'kembali', 'dan', 'tidak', 'ini', 'karena', 'kepada', 'oleh', 'saat', 'harus', 'sementara', 'setelah', 'belum', 'kami', 'sekitar', 'bagi', 'serta', 'di', 'dari', 'telah', 'sebagai', 'masih', 'hal', 'ketika', 'adalah', 'itu', 'dalam', 'bisa', 'bahwa', 'atau', 'hanya', 'kita', 'dengan', 'akan', 'juga', 'ada', 'mereka', 'sudah', 'saya', 'terhadap', 'secara', 'agar', 'lain', 'anda', 'begitu', 'mengapa', 'kenapa', 'yaitu', 'yakni', 'daripada', 'itulah', 'lagi', 'maka', 'tentang', 'demi', 'dimana', 'kemana', 'pula', 'sambil', 'sebelum', 'sesudah', 'supaya', 'guna', 'kah', 'pun', 'sampai', 'sedangkan', 'selagi', 'sementara', 'tetapi', 'apakah', 'kecuali', 'sebab', 'selain', 'seolah', 'seraya', 'seterusnya', 'tanpa', 'agak', 'boleh', 'dapat', 'dsb', 'dst', 'dll', 'dahulu', 'dulunya', 'anu', 'demikian', 'tapi', 'ingin', 'juga', 'nggak', 'mari', 'nanti', 'melainkan', 'oh', 'ok', 'seharusnya', 'sebetulnya', 'setiap', 'setidaknya', 'sesuatu', 'pasti', 'saja', 'toh', 'ya', 'walau', 'tolong', 'tentu', 'amat', 'apalagi', 'bagaimanapun']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwPkcTFKCBCO"
      },
      "source": [
        "# Loading Stopwords: Ada beberapa cara\n",
        "from nltk.corpus import stopwords\n",
        "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
        "factory = StopWordRemoverFactory()\n",
        "\n",
        "NLTK_StopWords = stopwords.words('english')\n",
        "Sastrawi_StopWords_id = factory.get_stop_words()\n",
        "\n",
        "with open('data/stopwords_eng.txt') as f:\n",
        "    content = f.readlines()\n",
        "    f.close()\n",
        "Personal_StopWords_en = [x.strip() for x in content] \n",
        "\n",
        "with open('data/stopwords_id.txt') as f:\n",
        "    content = f.readlines()\n",
        "    f.close()\n",
        "Personal_StopWords_id = [x.strip() for x in content] \n",
        "\n",
        "print(NLTK_StopWords[:5])\n",
        "print(Sastrawi_StopWords_id[:5])\n",
        "print(Personal_StopWords_en[:5])\n",
        "print(Personal_StopWords_id[:5])\n",
        "print(len(Sastrawi_StopWords_id), len(Personal_StopWords_id), len(NLTK_StopWords), len(Personal_StopWords_en))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJVW64UUCSIF"
      },
      "source": [
        "# Tips: selalu rubah list stopwords ke bentuk set, karena di Python jauh lebih cepat untuk cek existence di set ketimbang list\n",
        "NLTK_StopWords = set(NLTK_StopWords)\n",
        "Sastrawi_StopWords_id = set(Sastrawi_StopWords_id)\n",
        "Personal_StopWords_en = set(Personal_StopWords_en)\n",
        "Personal_StopWords_id = set(Personal_StopWords_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZFOsLgpCabV"
      },
      "source": [
        "# Cara menggunakan stopwords\n",
        "from textblob import TextBlob\n",
        "\n",
        "T = \"I am doing NLP at ITTC,... \\\n",
        "    adapun saya anu sedang belajar NLP di ITTC\"\n",
        "T = T.lower()\n",
        "Personal_StopWords_id.add('anu')\n",
        "Tokens = TextBlob(T).words # Tokenisasi \n",
        "T2 = [t for t in Tokens if t not in Personal_StopWords_id] # Sastrawi_StopWords_id Personal_StopWords_en Personal_StopWords_id\n",
        "T2 = [t for t in T2 if t not in Personal_StopWords_en] # Sastrawi_StopWords_id Personal_StopWords_en Personal_StopWords_id\n",
        "# T2 = [t for t in T2 if t not in NLTK_StopWords] # Sastrawi_StopWords_id Personal_StopWords_en Personal_StopWords_id\n",
        "# T2 = [t for t in T2 if t not in Sastrawi_StopWords_id] # Sastrawi_StopWords_id Personal_StopWords_en Personal_StopWords_id\n",
        "print(' '.join(T2))\n",
        "# Catatan: Selalu lakukan Stopword filtering setelah tokenisasi (dan normalisasi)."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}